{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7088831,"sourceType":"datasetVersion","datasetId":4084615}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torchvision\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nfrom torch.autograd import Variable\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\nfrom collections import Counter\nfrom skimage import io\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:30:53.856506Z","iopub.execute_input":"2023-12-24T17:30:53.856929Z","iopub.status.idle":"2023-12-24T17:31:01.761764Z","shell.execute_reply.started":"2023-12-24T17:30:53.856881Z","shell.execute_reply":"2023-12-24T17:31:01.761008Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# В этом ноутбуке будет приведен пример обучения модели без аугментации и преобразований данных. ","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/dataset/train')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:01.763628Z","iopub.execute_input":"2023-12-24T17:31:01.764181Z","iopub.status.idle":"2023-12-24T17:31:01.796671Z","shell.execute_reply.started":"2023-12-24T17:31:01.764143Z","shell.execute_reply":"2023-12-24T17:31:01.795893Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['neutral', 'sad', 'surprised', 'happy']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Буден создат датасет с сбалансированными данными (~3000 на каждый класс). Пришлось избавиться от части данных, чтобы выровнить их. \n# В дальнейшем будем пытаться решить эту проблему агументацией","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=['image', 'label'])\n\nfor i, label in enumerate(os.listdir('/kaggle/input/dataset/train')):\n    for img in os.listdir(f'/kaggle/input/dataset/train/{label}'):\n        df.loc[len(df)] = [f'/kaggle/input/dataset/train/{label}/{img}', i]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:01.797559Z","iopub.execute_input":"2023-12-24T17:31:01.797794Z","iopub.status.idle":"2023-12-24T17:31:25.855082Z","shell.execute_reply.started":"2023-12-24T17:31:01.797773Z","shell.execute_reply":"2023-12-24T17:31:25.854109Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.857726Z","iopub.execute_input":"2023-12-24T17:31:25.858382Z","iopub.status.idle":"2023-12-24T17:31:25.872341Z","shell.execute_reply.started":"2023-12-24T17:31:25.858345Z","shell.execute_reply":"2023-12-24T17:31:25.871439Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.873377Z","iopub.execute_input":"2023-12-24T17:31:25.873700Z","iopub.status.idle":"2023-12-24T17:31:25.890056Z","shell.execute_reply.started":"2023-12-24T17:31:25.873668Z","shell.execute_reply":"2023-12-24T17:31:25.889186Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"label\n3    7215\n0    4965\n1    4830\n2    3171\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"rows_to_drop = df[df['label'] == 3].index[:4000]\ndf = df.drop(rows_to_drop)\n\nrows_to_drop = df[df['label'] == 1].index[:1700]\ndf = df.drop(rows_to_drop)\n\nrows_to_drop = df[df['label'] == 0].index[:1800]\ndf = df.drop(rows_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.891164Z","iopub.execute_input":"2023-12-24T17:31:25.891467Z","iopub.status.idle":"2023-12-24T17:31:25.905104Z","shell.execute_reply.started":"2023-12-24T17:31:25.891444Z","shell.execute_reply":"2023-12-24T17:31:25.904404Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Размер данных по классам","metadata":{}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.905998Z","iopub.execute_input":"2023-12-24T17:31:25.906233Z","iopub.status.idle":"2023-12-24T17:31:25.912715Z","shell.execute_reply.started":"2023-12-24T17:31:25.906212Z","shell.execute_reply":"2023-12-24T17:31:25.911882Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"label\n3    3215\n2    3171\n0    3165\n1    3130\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['image'], df.label, test_size=0.33, random_state=42, stratify=df.label)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.913980Z","iopub.execute_input":"2023-12-24T17:31:25.914240Z","iopub.status.idle":"2023-12-24T17:31:25.932764Z","shell.execute_reply.started":"2023-12-24T17:31:25.914217Z","shell.execute_reply":"2023-12-24T17:31:25.931860Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pd.concat([X_train, y_train], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:25.933876Z","iopub.execute_input":"2023-12-24T17:31:25.934176Z","iopub.status.idle":"2023-12-24T17:31:25.949030Z","shell.execute_reply.started":"2023-12-24T17:31:25.934153Z","shell.execute_reply":"2023-12-24T17:31:25.948263Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  image  label\n14391      /kaggle/input/dataset/train/happy/im3683.png      3\n1044     /kaggle/input/dataset/train/neutral/im1667.png      0\n11979  /kaggle/input/dataset/train/surprised/im1230.png      2\n14969       /kaggle/input/dataset/train/happy/im699.png      3\n13796      /kaggle/input/dataset/train/happy/im1898.png      3\n...                                                 ...    ...\n4432     /kaggle/input/dataset/train/neutral/im2691.png      0\n19212      /kaggle/input/dataset/train/happy/im6689.png      3\n16923      /kaggle/input/dataset/train/happy/im2255.png      3\n7388         /kaggle/input/dataset/train/sad/im2181.png      1\n10609   /kaggle/input/dataset/train/surprised/im668.png      2\n\n[8496 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14391</th>\n      <td>/kaggle/input/dataset/train/happy/im3683.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1044</th>\n      <td>/kaggle/input/dataset/train/neutral/im1667.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11979</th>\n      <td>/kaggle/input/dataset/train/surprised/im1230.png</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14969</th>\n      <td>/kaggle/input/dataset/train/happy/im699.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13796</th>\n      <td>/kaggle/input/dataset/train/happy/im1898.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4432</th>\n      <td>/kaggle/input/dataset/train/neutral/im2691.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19212</th>\n      <td>/kaggle/input/dataset/train/happy/im6689.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16923</th>\n      <td>/kaggle/input/dataset/train/happy/im2255.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7388</th>\n      <td>/kaggle/input/dataset/train/sad/im2181.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10609</th>\n      <td>/kaggle/input/dataset/train/surprised/im668.png</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>8496 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        #row = self.dataframe.iloc[index]\n        image=io.imread(self.dataframe.iloc[index]['image'])\n        \n        rgb_image = np.zeros((48, 48, 3), dtype=np.uint8)\n\n        # Копируем одноканальное изображение в каждый канал RGB\n        rgb_image[:,:,0] = image  # Красный канал\n        rgb_image[:,:,1] = image  # Зеленый канал\n        rgb_image[:,:,2] = image  # Синий канал\n        image = rgb_image\n        \n        if self.transform:\n            image = self.transform(image)   \n        y_label=torch.tensor(float(self.dataframe.iloc[index]['label']))\n        return (image,y_label)\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize(256),\n        transforms.RandomHorizontalFlip(),\n        transforms.Normalize([0.51145715, 0.51145715, 0.51145715], [0.250773, 0.250773, 0.250773])\n        \n    ]),\n    'val': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize(256),\n        \n    ]),\n}\n\ntrain_data = MyDataset(pd.concat([X_train, y_train], axis=1), data_transforms['train'])\ntest_data = MyDataset(pd.concat([X_test, y_test], axis=1), data_transforms['val'])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:35:01.983837Z","iopub.execute_input":"2023-12-24T17:35:01.984686Z","iopub.status.idle":"2023-12-24T17:35:01.998819Z","shell.execute_reply.started":"2023-12-24T17:35:01.984653Z","shell.execute_reply":"2023-12-24T17:35:01.997907Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"io.imread(df.iloc[1]['image'])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:35:06.404077Z","iopub.execute_input":"2023-12-24T17:35:06.405031Z","iopub.status.idle":"2023-12-24T17:35:06.419839Z","shell.execute_reply.started":"2023-12-24T17:35:06.404990Z","shell.execute_reply":"2023-12-24T17:35:06.418884Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([[166, 167, 167, ..., 168, 169, 168],\n       [165, 167, 166, ..., 168, 167, 166],\n       [167, 167, 165, ..., 167, 167, 167],\n       ...,\n       [157, 130,  90, ...,  17,  35,  80],\n       [157, 148,  76, ...,  24,  40,  89],\n       [159, 158, 114, ...,  29,  49, 111]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"image_datasets = {'train' : train_data, 'val' : test_data}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:31:26.021570Z","iopub.execute_input":"2023-12-24T17:31:26.021844Z","iopub.status.idle":"2023-12-24T17:31:26.094263Z","shell.execute_reply.started":"2023-12-24T17:31:26.021822Z","shell.execute_reply":"2023-12-24T17:31:26.093285Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    labels = labels.type(torch.LongTensor)\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            optimizer.zero_grad()\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:31.435565Z","iopub.execute_input":"2023-12-24T18:15:31.435921Z","iopub.status.idle":"2023-12-24T18:15:31.450657Z","shell.execute_reply.started":"2023-12-24T18:15:31.435874Z","shell.execute_reply":"2023-12-24T18:15:31.449777Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n    class_names = ['neutral', 'sad', 'surprised', 'happy']\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                plt.imshow(inputs.cpu().data[j].permute(1, 2, 0))\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:32.575424Z","iopub.execute_input":"2023-12-24T18:15:32.575802Z","iopub.status.idle":"2023-12-24T18:15:32.584531Z","shell.execute_reply.started":"2023-12-24T18:15:32.575771Z","shell.execute_reply":"2023-12-24T18:15:32.583602Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# В качестве модели, методом подбора, самые лучшие результаты показала архитектура EfficientNet","metadata":{"execution":{"iopub.status.busy":"2023-12-25T13:29:54.294000Z","iopub.execute_input":"2023-12-25T13:29:54.294373Z","iopub.status.idle":"2023-12-25T13:29:54.299749Z","shell.execute_reply.started":"2023-12-25T13:29:54.294346Z","shell.execute_reply":"2023-12-25T13:29:54.298650Z"}}},{"cell_type":"code","source":"model_ft = models.efficientnet_b1(torchvision.models.EfficientNet_B1_Weights.IMAGENET1K_V2)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:33.671044Z","iopub.execute_input":"2023-12-24T18:15:33.671391Z","iopub.status.idle":"2023-12-24T18:15:33.897166Z","shell.execute_reply.started":"2023-12-24T18:15:33.671364Z","shell.execute_reply":"2023-12-24T18:15:33.896182Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model_ft.classifier[-1] = nn.Linear(in_features=1280, out_features=4, bias=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:37.812137Z","iopub.execute_input":"2023-12-24T18:15:37.812499Z","iopub.status.idle":"2023-12-24T18:15:37.817868Z","shell.execute_reply.started":"2023-12-24T18:15:37.812470Z","shell.execute_reply":"2023-12-24T18:15:37.816963Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model_ft = model_ft.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:38.695672Z","iopub.execute_input":"2023-12-24T18:15:38.696296Z","iopub.status.idle":"2023-12-24T18:15:38.723862Z","shell.execute_reply.started":"2023-12-24T18:15:38.696263Z","shell.execute_reply":"2023-12-24T18:15:38.723006Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:40.481019Z","iopub.execute_input":"2023-12-24T18:15:40.481376Z","iopub.status.idle":"2023-12-24T18:15:40.492793Z","shell.execute_reply.started":"2023-12-24T18:15:40.481348Z","shell.execute_reply":"2023-12-24T18:15:40.491821Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=20);","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:15:52.082361Z","iopub.execute_input":"2023-12-24T18:15:52.082729Z","iopub.status.idle":"2023-12-24T18:43:26.673407Z","shell.execute_reply.started":"2023-12-24T18:15:52.082698Z","shell.execute_reply":"2023-12-24T18:43:26.672341Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 0/19\n----------\ntrain Loss: 0.8252 Acc: 0.6581\nval Loss: 0.6496 Acc: 0.7417\n\nEpoch 1/19\n----------\ntrain Loss: 0.6027 Acc: 0.7648\nval Loss: 0.5871 Acc: 0.7704\n\nEpoch 2/19\n----------\ntrain Loss: 0.4891 Acc: 0.8028\nval Loss: 0.6707 Acc: 0.7446\n\nEpoch 3/19\n----------\ntrain Loss: 0.3986 Acc: 0.8452\nval Loss: 0.6652 Acc: 0.7622\n\nEpoch 4/19\n----------\ntrain Loss: 0.3393 Acc: 0.8696\nval Loss: 0.6962 Acc: 0.7513\n\nEpoch 5/19\n----------\ntrain Loss: 0.2874 Acc: 0.8889\nval Loss: 0.6718 Acc: 0.7804\n\nEpoch 6/19\n----------\ntrain Loss: 0.2224 Acc: 0.9144\nval Loss: 0.6986 Acc: 0.7900\n\nEpoch 7/19\n----------\ntrain Loss: 0.1110 Acc: 0.9628\nval Loss: 0.6928 Acc: 0.8014\n\nEpoch 8/19\n----------\ntrain Loss: 0.0699 Acc: 0.9770\nval Loss: 0.7436 Acc: 0.8062\n\nEpoch 9/19\n----------\ntrain Loss: 0.0578 Acc: 0.9803\nval Loss: 0.7806 Acc: 0.8086\n\nEpoch 10/19\n----------\ntrain Loss: 0.0430 Acc: 0.9861\nval Loss: 0.8297 Acc: 0.8067\n\nEpoch 11/19\n----------\ntrain Loss: 0.0374 Acc: 0.9886\nval Loss: 0.8549 Acc: 0.8103\n\nEpoch 12/19\n----------\ntrain Loss: 0.0334 Acc: 0.9887\nval Loss: 0.8910 Acc: 0.8079\n\nEpoch 13/19\n----------\ntrain Loss: 0.0252 Acc: 0.9925\nval Loss: 0.9178 Acc: 0.8062\n\nEpoch 14/19\n----------\ntrain Loss: 0.0230 Acc: 0.9931\nval Loss: 0.9233 Acc: 0.8079\n\nEpoch 15/19\n----------\ntrain Loss: 0.0213 Acc: 0.9936\nval Loss: 0.9295 Acc: 0.8067\n\nEpoch 16/19\n----------\ntrain Loss: 0.0239 Acc: 0.9940\nval Loss: 0.9260 Acc: 0.8074\n\nEpoch 17/19\n----------\ntrain Loss: 0.0214 Acc: 0.9938\nval Loss: 0.9285 Acc: 0.8072\n\nEpoch 18/19\n----------\ntrain Loss: 0.0221 Acc: 0.9926\nval Loss: 0.9321 Acc: 0.8074\n\nEpoch 19/19\n----------\ntrain Loss: 0.0201 Acc: 0.9949\nval Loss: 0.9402 Acc: 0.8074\n\nTraining complete in 27m 34s\nBest val Acc: 0.810275\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Максимальная точность на валидационной выборке составила 80%. На тестовой может быть чуть поменьше. В других ноутбуках будет попробована аугментация и различные архитектуры","metadata":{}}]}